[03/08 06:03:42] detectron2 INFO: Rank of current process: 1. World size: 3
[03/08 06:03:44] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/08 06:03:44] detectron2 INFO: Command line arguments: Namespace(config_file='configs/PanopticFCN-R50-1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=3, num_machines=1, opts=[], output=None, resume=False)
[03/08 06:03:44] detectron2 INFO: Contents of args.config_file=configs/PanopticFCN-R50-1x.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "/data/detectron2_modelzoo/basemodel/R-50-MSRA.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
DATASETS:
  #TRAIN: ("coco_2017_train_panoptic_separated",)
  #TEST: ("coco_2017_val_panoptic_separated",)
  TRAIN: ("cityscapes_fine_panoptic_train",)
  TEST: ("cityscapes_fine_panoptic_val",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
SOLVER:
  BASE_LR: 0.01
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 35.0
  IMS_PER_BATCH: 16
  MAX_ITER: 90000
  CHECKPOINT_PERIOD: 10000
INPUT:
  MIN_SIZE_TRAIN: (640, 672, 704, 736, 768, 800)
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 800
  MAX_SIZE_TRAIN: 1333
  MAX_SIZE_TEST: 1333
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/08 06:03:44] detectron2.utils.env INFO: Using a generated random seed 47145942
[03/08 06:03:45] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/08 06:03:45] detectron2.data.datasets.cityscapes_panoptic INFO: 18 cities found in 'datasets/cityscapes/leftImg8bit/train'.
[03/08 06:03:45] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[03/08 06:03:45] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/08 06:03:45] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/08 06:03:45] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/08 06:03:45] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/17 02:47:46] detectron2 INFO: Rank of current process: 1. World size: 2
[03/17 02:47:49] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/17 02:47:49] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/17 02:47:49] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 1000
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/17 02:47:49] detectron2.utils.env INFO: Using a generated random seed 52172491
[03/17 02:47:50] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/17 02:49:05] detectron2 INFO: Rank of current process: 1. World size: 2
[03/17 02:49:07] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/17 02:49:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/17 02:49:07] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 1000
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/17 02:49:07] detectron2.utils.env INFO: Using a generated random seed 10940572
[03/17 02:49:09] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/17 02:49:10] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/17 02:49:10] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/17 02:49:10] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/17 02:49:10] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/17 02:49:10] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/17 02:49:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/17 02:49:10] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/17 02:49:10] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/17 02:49:10] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/17 02:49:10] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/17 02:49:10] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/17 03:53:33] detectron2.engine.hooks INFO: Overall training speed: 998 iterations in 1:03:50 (3.8380 s / it)
[03/17 03:53:33] detectron2.engine.hooks INFO: Total training time: 1:03:50 (0:00:00 on hooks)
[03/17 03:53:33] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[03/17 03:53:33] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/17 03:53:33] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[03/17 03:53:33] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[03/17 03:53:33] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[03/17 03:53:44] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0044 s/iter. Inference: 0.1555 s/iter. Eval: 0.1627 s/iter. Total: 0.3227 s/iter. ETA=0:01:17
[03/17 03:53:49] detectron2.evaluation.evaluator INFO: Inference done 28/250. Dataloading: 0.0066 s/iter. Inference: 0.1484 s/iter. Eval: 0.1591 s/iter. Total: 0.3142 s/iter. ETA=0:01:09
[03/17 03:53:54] detectron2.evaluation.evaluator INFO: Inference done 45/250. Dataloading: 0.0062 s/iter. Inference: 0.1441 s/iter. Eval: 0.1562 s/iter. Total: 0.3065 s/iter. ETA=0:01:02
[03/17 03:53:59] detectron2.evaluation.evaluator INFO: Inference done 63/250. Dataloading: 0.0063 s/iter. Inference: 0.1418 s/iter. Eval: 0.1537 s/iter. Total: 0.3019 s/iter. ETA=0:00:56
[03/17 03:54:05] detectron2.evaluation.evaluator INFO: Inference done 81/250. Dataloading: 0.0062 s/iter. Inference: 0.1410 s/iter. Eval: 0.1521 s/iter. Total: 0.2995 s/iter. ETA=0:00:50
[03/17 03:54:10] detectron2.evaluation.evaluator INFO: Inference done 98/250. Dataloading: 0.0063 s/iter. Inference: 0.1421 s/iter. Eval: 0.1529 s/iter. Total: 0.3015 s/iter. ETA=0:00:45
[03/17 03:54:15] detectron2.evaluation.evaluator INFO: Inference done 115/250. Dataloading: 0.0064 s/iter. Inference: 0.1424 s/iter. Eval: 0.1522 s/iter. Total: 0.3012 s/iter. ETA=0:00:40
[03/17 03:54:20] detectron2.evaluation.evaluator INFO: Inference done 132/250. Dataloading: 0.0065 s/iter. Inference: 0.1431 s/iter. Eval: 0.1519 s/iter. Total: 0.3017 s/iter. ETA=0:00:35
[03/17 03:54:25] detectron2.evaluation.evaluator INFO: Inference done 149/250. Dataloading: 0.0065 s/iter. Inference: 0.1434 s/iter. Eval: 0.1515 s/iter. Total: 0.3016 s/iter. ETA=0:00:30
[03/17 05:27:03] detectron2.evaluation.evaluator INFO: Inference done 163/250. Dataloading: 0.0065 s/iter. Inference: 35.2930 s/iter. Eval: 0.1516 s/iter. Total: 35.4512 s/iter. ETA=0:51:24
[03/17 05:27:08] detectron2.evaluation.evaluator INFO: Inference done 179/250. Dataloading: 0.0068 s/iter. Inference: 32.0625 s/iter. Eval: 0.1518 s/iter. Total: 32.2212 s/iter. ETA=0:38:07
[03/17 05:27:13] detectron2.evaluation.evaluator INFO: Inference done 195/250. Dataloading: 0.0069 s/iter. Inference: 29.3751 s/iter. Eval: 0.1525 s/iter. Total: 29.5347 s/iter. ETA=0:27:04
[03/17 05:27:19] detectron2.evaluation.evaluator INFO: Inference done 212/250. Dataloading: 0.0070 s/iter. Inference: 26.9744 s/iter. Eval: 0.1529 s/iter. Total: 27.1346 s/iter. ETA=0:17:11
[03/17 05:27:24] detectron2.evaluation.evaluator INFO: Inference done 229/250. Dataloading: 0.0070 s/iter. Inference: 24.9385 s/iter. Eval: 0.1524 s/iter. Total: 25.0980 s/iter. ETA=0:08:47
[03/17 05:27:29] detectron2.evaluation.evaluator INFO: Inference done 247/250. Dataloading: 0.0070 s/iter. Inference: 23.0938 s/iter. Eval: 0.1516 s/iter. Total: 23.2525 s/iter. ETA=0:01:09
[03/17 05:27:31] detectron2.evaluation.evaluator INFO: Total inference time: 1:33:49.022201 (22.975601 s / iter per device, on 2 devices)
[03/17 05:27:31] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 1:33:09 (22.812605 s / iter per device, on 2 devices)
[03/17 05:36:17] detectron2 INFO: Rank of current process: 1. World size: 2
[03/17 05:36:18] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/17 05:36:18] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/17 05:36:18] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 65000 #origin
  # MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/17 05:36:18] detectron2.utils.env INFO: Using a generated random seed 22104988
[03/17 05:36:19] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/17 05:36:20] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/17 05:36:20] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/17 05:36:20] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/17 05:36:20] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/17 05:36:20] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/17 05:36:20] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/17 05:36:20] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/17 05:36:20] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/17 05:36:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/17 05:36:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/17 05:36:20] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/20 00:42:26] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 00:42:28] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 00:42:28] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 00:42:28] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 65000 #origin
  # MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 00:42:28] detectron2.utils.env INFO: Using a generated random seed 30386763
[03/20 00:42:28] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/20 00:42:29] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/20 00:42:29] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 00:42:29] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/20 00:42:29] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/20 00:42:29] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 00:42:29] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 00:42:30] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 00:42:30] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 00:42:30] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 00:42:30] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 00:42:30] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/20 00:48:32] detectron2.engine.hooks INFO: Overall training speed: 83 iterations in 0:05:27 (3.9462 s / it)
[03/20 00:48:32] detectron2.engine.hooks INFO: Total training time: 0:05:27 (0:00:00 on hooks)
[03/20 01:24:17] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 01:24:18] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 01:24:18] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 01:24:18] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 65000 #origin
  # MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 01:24:19] detectron2.utils.env INFO: Using a generated random seed 21253988
[03/20 01:24:19] detectron2 INFO: Arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 01:24:19] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:24:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:24:20] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 01:24:20] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 01:24:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 01:24:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 01:24:20] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/20 01:24:21] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/20 01:24:21] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 01:24:21] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/20 01:24:21] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/20 01:24:21] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:24:21] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:24:21] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 01:24:21] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 01:24:21] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 01:24:21] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 01:24:21] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/20 01:28:15] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 01:28:17] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 01:28:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 01:28:17] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  # MAX_ITER: 65000 #origin
  MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 01:28:17] detectron2.utils.env INFO: Using a generated random seed 19394530
[03/20 01:28:17] detectron2 INFO: Arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 01:28:17] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:28:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:28:18] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 01:28:18] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 01:28:18] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 01:28:18] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 01:28:18] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/20 01:28:19] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/20 01:28:19] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 01:28:19] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/20 01:28:19] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/20 01:28:19] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:28:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 01:28:19] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 01:28:19] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 01:28:19] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 01:28:19] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 01:28:19] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/20 02:20:36] detectron2.engine.hooks INFO: Overall training speed: 998 iterations in 0:51:52 (3.1182 s / it)
[03/20 02:20:36] detectron2.engine.hooks INFO: Total training time: 0:51:52 (0:00:00 on hooks)
[03/20 02:20:37] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[03/20 02:20:37] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 02:20:37] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[03/20 02:20:37] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[03/20 02:20:37] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[03/20 02:20:45] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0025 s/iter. Inference: 0.1313 s/iter. Eval: 0.1253 s/iter. Total: 0.2592 s/iter. ETA=0:01:01
[03/20 02:20:50] detectron2.evaluation.evaluator INFO: Inference done 31/250. Dataloading: 0.0033 s/iter. Inference: 0.1270 s/iter. Eval: 0.1221 s/iter. Total: 0.2526 s/iter. ETA=0:00:55
[03/20 02:20:55] detectron2.evaluation.evaluator INFO: Inference done 52/250. Dataloading: 0.0038 s/iter. Inference: 0.1240 s/iter. Eval: 0.1217 s/iter. Total: 0.2496 s/iter. ETA=0:00:49
[03/20 02:21:00] detectron2.evaluation.evaluator INFO: Inference done 73/250. Dataloading: 0.0039 s/iter. Inference: 0.1230 s/iter. Eval: 0.1208 s/iter. Total: 0.2478 s/iter. ETA=0:00:43
[03/20 02:21:05] detectron2.evaluation.evaluator INFO: Inference done 93/250. Dataloading: 0.0040 s/iter. Inference: 0.1245 s/iter. Eval: 0.1211 s/iter. Total: 0.2497 s/iter. ETA=0:00:39
[03/20 02:21:10] detectron2.evaluation.evaluator INFO: Inference done 113/250. Dataloading: 0.0041 s/iter. Inference: 0.1255 s/iter. Eval: 0.1211 s/iter. Total: 0.2507 s/iter. ETA=0:00:34
[03/20 02:21:16] detectron2.evaluation.evaluator INFO: Inference done 133/250. Dataloading: 0.0041 s/iter. Inference: 0.1267 s/iter. Eval: 0.1211 s/iter. Total: 0.2519 s/iter. ETA=0:00:29
[03/20 02:21:21] detectron2.evaluation.evaluator INFO: Inference done 153/250. Dataloading: 0.0041 s/iter. Inference: 0.1274 s/iter. Eval: 0.1211 s/iter. Total: 0.2526 s/iter. ETA=0:00:24
[03/20 02:21:26] detectron2.evaluation.evaluator INFO: Inference done 173/250. Dataloading: 0.0041 s/iter. Inference: 0.1276 s/iter. Eval: 0.1211 s/iter. Total: 0.2530 s/iter. ETA=0:00:19
[03/20 02:21:31] detectron2.evaluation.evaluator INFO: Inference done 193/250. Dataloading: 0.0041 s/iter. Inference: 0.1275 s/iter. Eval: 0.1212 s/iter. Total: 0.2529 s/iter. ETA=0:00:14
[03/20 02:21:36] detectron2.evaluation.evaluator INFO: Inference done 213/250. Dataloading: 0.0041 s/iter. Inference: 0.1274 s/iter. Eval: 0.1211 s/iter. Total: 0.2526 s/iter. ETA=0:00:09
[03/20 02:21:41] detectron2.evaluation.evaluator INFO: Inference done 233/250. Dataloading: 0.0041 s/iter. Inference: 0.1279 s/iter. Eval: 0.1207 s/iter. Total: 0.2528 s/iter. ETA=0:00:04
[03/20 02:21:46] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:02.849764 (0.256530 s / iter per device, on 2 devices)
[03/20 02:21:46] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:31 (0.127671 s / iter per device, on 2 devices)
[03/20 02:27:12] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 02:27:14] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 02:27:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=['datasets/cityscapes/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000002_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000003_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000004_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000005_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000006_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000007_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000008_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000009_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000010_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000011_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000012_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000013_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000014_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000015_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000016_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000017_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000018_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000019_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000020_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000021_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000022_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000023_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000024_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000025_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000026_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000027_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000028_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000029_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000030_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000031_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000032_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000033_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000034_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000035_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000036_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000037_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000038_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000039_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000040_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000041_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000042_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000043_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000044_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000045_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000046_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000047_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000048_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000049_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000050_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000051_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000052_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000053_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000054_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000055_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000056_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000057_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000058_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000059_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000060_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000061_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000062_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000063_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000064_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000065_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000066_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000067_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000068_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000069_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000070_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000071_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000072_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000073_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000074_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000075_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000076_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000077_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000078_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000079_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000080_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000081_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000082_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000083_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000084_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000085_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000086_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000087_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000088_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000089_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000090_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000091_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000092_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000093_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000094_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000095_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000096_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000097_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000098_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000099_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000100_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000101_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000102_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000103_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000104_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000105_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000106_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000107_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000108_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000109_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000110_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000111_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000112_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000113_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000114_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000115_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000116_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000117_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000118_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000119_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000120_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000121_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000122_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000123_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000124_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000125_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000126_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000127_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000128_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000129_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000130_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000131_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000132_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000133_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000134_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000135_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000136_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000137_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000138_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000139_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000140_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000141_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000142_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000143_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000144_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000145_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000146_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000147_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000148_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000149_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000150_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000151_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000152_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000153_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000154_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000155_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000156_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000157_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000158_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000159_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000160_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000161_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000162_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000163_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000164_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000165_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000166_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000167_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000168_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000169_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000170_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000171_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000172_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000173_000019_leftImg8bit.png'], machine_rank=0, num_gpus=2, num_machines=1, opts=[], output='output/results/test/', resume=False)
[03/20 02:27:14] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  # MAX_ITER: 65000 #origin
  MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 02:27:14] detectron2.utils.env INFO: Using a generated random seed 16386923
[03/20 02:27:14] detectron2 INFO: Arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=['datasets/cityscapes/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000002_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000003_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000004_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000005_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000006_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000007_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000008_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000009_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000010_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000011_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000012_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000013_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000014_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000015_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000016_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000017_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000018_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000019_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000020_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000021_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000022_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000023_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000024_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000025_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000026_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000027_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000028_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000029_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000030_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000031_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000032_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000033_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000034_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000035_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000036_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000037_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000038_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000039_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000040_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000041_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000042_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000043_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000044_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000045_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000046_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000047_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000048_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000049_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000050_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000051_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000052_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000053_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000054_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000055_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000056_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000057_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000058_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000059_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000060_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000061_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000062_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000063_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000064_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000065_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000066_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000067_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000068_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000069_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000070_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000071_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000072_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000073_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000074_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000075_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000076_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000077_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000078_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000079_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000080_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000081_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000082_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000083_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000084_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000085_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000086_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000087_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000088_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000089_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000090_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000091_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000092_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000093_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000094_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000095_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000096_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000097_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000098_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000099_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000100_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000101_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000102_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000103_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000104_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000105_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000106_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000107_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000108_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000109_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000110_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000111_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000112_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000113_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000114_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000115_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000116_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000117_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000118_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000119_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000120_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000121_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000122_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000123_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000124_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000125_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000126_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000127_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000128_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000129_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000130_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000131_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000132_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000133_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000134_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000135_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000136_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000137_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000138_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000139_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000140_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000141_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000142_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000143_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000144_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000145_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000146_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000147_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000148_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000149_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000150_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000151_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000152_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000153_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000154_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000155_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000156_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000157_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000158_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000159_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000160_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000161_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000162_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000163_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000164_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000165_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000166_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000167_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000168_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000169_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000170_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000171_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000172_000019_leftImg8bit.png', 'datasets/cityscapes/leftImg8bit/train/aachen/aachen_000173_000019_leftImg8bit.png'], machine_rank=0, num_gpus=2, num_machines=1, opts=[], output='output/results/test/', resume=False)
[03/20 02:27:14] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 02:27:14] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 02:27:15] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 02:27:15] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 02:27:15] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 02:27:15] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 02:27:21] detectron2 INFO: datasets/cityscapes/leftImg8bit/train/aachen/aachen_000000_000019_leftImg8bit.png: detected 200 instances in 6.32s
[03/20 02:27:22] detectron2 INFO: datasets/cityscapes/leftImg8bit/train/aachen/aachen_000001_000019_leftImg8bit.png: detected 200 instances in 0.73s
[03/20 09:07:50] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 09:07:51] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 09:07:51] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 09:07:51] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  # MAX_ITER: 65000 #origin
  MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 09:07:51] detectron2.utils.env INFO: Using a generated random seed 54531177
[03/20 09:07:52] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/20 09:07:52] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/20 09:07:52] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 09:07:52] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/20 09:07:52] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/20 09:07:52] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 09:07:52] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 09:07:53] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 09:07:53] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 09:07:53] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 09:07:53] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 09:07:53] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/20 09:12:23] detectron2.engine.hooks INFO: Overall training speed: 88 iterations in 0:04:11 (2.8531 s / it)
[03/20 09:12:23] detectron2.engine.hooks INFO: Total training time: 0:04:11 (0:00:00 on hooks)
[03/20 09:12:47] detectron2 INFO: Rank of current process: 1. World size: 2
[03/20 09:12:48] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.7.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[03/20 09:12:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[03/20 09:12:48] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 19 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 12 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 12 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 32
  MAX_ITER: 65000 #origin
  # MAX_ITER: 1000 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[03/20 09:12:48] detectron2.utils.env INFO: Using a generated random seed 51045767
[03/20 09:12:48] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[03/20 09:12:49] detectron2.data.build INFO: Using training sampler TrainingSampler
[03/20 09:12:49] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/20 09:12:49] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[03/20 09:12:49] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[03/20 09:12:49] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 09:12:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[03/20 09:12:49] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[03/20 09:12:49] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[03/20 09:12:49] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[03/20 09:12:49] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[03/20 09:12:49] detectron2.engine.train_loop INFO: Starting training from iteration 0
[03/22 20:04:14] detectron2.engine.hooks INFO: Overall training speed: 64998 iterations in 2 days, 10:50:56 (3.2594 s / it)
[03/22 20:04:14] detectron2.engine.hooks INFO: Total training time: 2 days, 10:51:07 (0:00:10 on hooks)
[03/22 20:04:14] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[03/22 20:04:14] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[03/22 20:04:14] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[03/22 20:04:14] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[03/22 20:04:14] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[03/22 20:04:22] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0040 s/iter. Inference: 0.1272 s/iter. Eval: 0.1257 s/iter. Total: 0.2569 s/iter. ETA=0:01:01
[03/22 20:04:27] detectron2.evaluation.evaluator INFO: Inference done 32/250. Dataloading: 0.0036 s/iter. Inference: 0.1241 s/iter. Eval: 0.1207 s/iter. Total: 0.2485 s/iter. ETA=0:00:54
[03/22 20:04:32] detectron2.evaluation.evaluator INFO: Inference done 53/250. Dataloading: 0.0037 s/iter. Inference: 0.1208 s/iter. Eval: 0.1200 s/iter. Total: 0.2446 s/iter. ETA=0:00:48
[03/22 20:04:37] detectron2.evaluation.evaluator INFO: Inference done 75/250. Dataloading: 0.0038 s/iter. Inference: 0.1187 s/iter. Eval: 0.1188 s/iter. Total: 0.2413 s/iter. ETA=0:00:42
[03/22 20:04:42] detectron2.evaluation.evaluator INFO: Inference done 95/250. Dataloading: 0.0038 s/iter. Inference: 0.1207 s/iter. Eval: 0.1190 s/iter. Total: 0.2436 s/iter. ETA=0:00:37
[03/22 20:04:47] detectron2.evaluation.evaluator INFO: Inference done 115/250. Dataloading: 0.0039 s/iter. Inference: 0.1222 s/iter. Eval: 0.1192 s/iter. Total: 0.2454 s/iter. ETA=0:00:33
[03/22 20:04:53] detectron2.evaluation.evaluator INFO: Inference done 135/250. Dataloading: 0.0039 s/iter. Inference: 0.1238 s/iter. Eval: 0.1194 s/iter. Total: 0.2471 s/iter. ETA=0:00:28
[03/22 20:04:58] detectron2.evaluation.evaluator INFO: Inference done 155/250. Dataloading: 0.0039 s/iter. Inference: 0.1244 s/iter. Eval: 0.1193 s/iter. Total: 0.2477 s/iter. ETA=0:00:23
[03/22 20:05:03] detectron2.evaluation.evaluator INFO: Inference done 175/250. Dataloading: 0.0039 s/iter. Inference: 0.1247 s/iter. Eval: 0.1194 s/iter. Total: 0.2481 s/iter. ETA=0:00:18
[03/22 20:05:08] detectron2.evaluation.evaluator INFO: Inference done 196/250. Dataloading: 0.0039 s/iter. Inference: 0.1246 s/iter. Eval: 0.1193 s/iter. Total: 0.2478 s/iter. ETA=0:00:13
[03/22 20:05:13] detectron2.evaluation.evaluator INFO: Inference done 217/250. Dataloading: 0.0039 s/iter. Inference: 0.1244 s/iter. Eval: 0.1193 s/iter. Total: 0.2477 s/iter. ETA=0:00:08
[03/22 20:05:18] detectron2.evaluation.evaluator INFO: Inference done 238/250. Dataloading: 0.0039 s/iter. Inference: 0.1247 s/iter. Eval: 0.1189 s/iter. Total: 0.2476 s/iter. ETA=0:00:02
[03/22 20:05:22] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:01.546766 (0.251211 s / iter per device, on 2 devices)
[03/22 20:05:22] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.124986 s / iter per device, on 2 devices)
[04/05 01:36:41] detectron2 INFO: Rank of current process: 1. World size: 2
[04/05 01:36:43] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/05 01:36:43] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[04/05 01:36:43] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 6 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 17 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 17 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 16
  # MAX_ITER: 65000 #origin
  MAX_ITER: 500 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[04/05 01:36:43] detectron2.utils.env INFO: Using a generated random seed 44907036
[04/05 01:36:43] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[04/05 01:36:44] detectron2.data.build INFO: Using training sampler TrainingSampler
[04/05 01:36:44] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 01:36:44] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[04/05 01:36:44] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[04/05 01:36:44] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 01:36:44] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 01:36:44] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[04/05 01:36:44] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[04/05 01:36:44] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[04/05 01:36:44] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[04/05 01:36:44] detectron2.engine.train_loop INFO: Starting training from iteration 0
[04/05 01:50:28] detectron2.engine.hooks INFO: Overall training speed: 498 iterations in 0:13:28 (1.6242 s / it)
[04/05 01:50:28] detectron2.engine.hooks INFO: Total training time: 0:13:28 (0:00:00 on hooks)
[04/05 01:50:28] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[04/05 01:50:28] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 01:50:28] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[04/05 01:50:28] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[04/05 01:50:28] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[04/05 01:50:35] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0074 s/iter. Inference: 0.1431 s/iter. Eval: 0.1934 s/iter. Total: 0.3440 s/iter. ETA=0:01:22
[04/05 01:50:40] detectron2.evaluation.evaluator INFO: Inference done 33/250. Dataloading: 0.0042 s/iter. Inference: 0.1231 s/iter. Eval: 0.1302 s/iter. Total: 0.2575 s/iter. ETA=0:00:55
[04/05 01:50:46] detectron2.evaluation.evaluator INFO: Inference done 55/250. Dataloading: 0.0041 s/iter. Inference: 0.1203 s/iter. Eval: 0.1233 s/iter. Total: 0.2477 s/iter. ETA=0:00:48
[04/05 01:50:51] detectron2.evaluation.evaluator INFO: Inference done 77/250. Dataloading: 0.0041 s/iter. Inference: 0.1191 s/iter. Eval: 0.1210 s/iter. Total: 0.2442 s/iter. ETA=0:00:42
[04/05 01:50:56] detectron2.evaluation.evaluator INFO: Inference done 98/250. Dataloading: 0.0041 s/iter. Inference: 0.1196 s/iter. Eval: 0.1198 s/iter. Total: 0.2436 s/iter. ETA=0:00:37
[04/05 01:51:01] detectron2.evaluation.evaluator INFO: Inference done 119/250. Dataloading: 0.0042 s/iter. Inference: 0.1200 s/iter. Eval: 0.1191 s/iter. Total: 0.2434 s/iter. ETA=0:00:31
[04/05 01:51:06] detectron2.evaluation.evaluator INFO: Inference done 140/250. Dataloading: 0.0042 s/iter. Inference: 0.1202 s/iter. Eval: 0.1187 s/iter. Total: 0.2431 s/iter. ETA=0:00:26
[04/05 01:51:11] detectron2.evaluation.evaluator INFO: Inference done 161/250. Dataloading: 0.0043 s/iter. Inference: 0.1206 s/iter. Eval: 0.1186 s/iter. Total: 0.2437 s/iter. ETA=0:00:21
[04/05 01:51:16] detectron2.evaluation.evaluator INFO: Inference done 182/250. Dataloading: 0.0044 s/iter. Inference: 0.1209 s/iter. Eval: 0.1180 s/iter. Total: 0.2433 s/iter. ETA=0:00:16
[04/05 01:51:21] detectron2.evaluation.evaluator INFO: Inference done 203/250. Dataloading: 0.0044 s/iter. Inference: 0.1211 s/iter. Eval: 0.1173 s/iter. Total: 0.2429 s/iter. ETA=0:00:11
[04/05 01:51:26] detectron2.evaluation.evaluator INFO: Inference done 224/250. Dataloading: 0.0044 s/iter. Inference: 0.1215 s/iter. Eval: 0.1170 s/iter. Total: 0.2431 s/iter. ETA=0:00:06
[04/05 01:51:32] detectron2.evaluation.evaluator INFO: Inference done 246/250. Dataloading: 0.0044 s/iter. Inference: 0.1214 s/iter. Eval: 0.1160 s/iter. Total: 0.2419 s/iter. ETA=0:00:00
[04/05 01:51:33] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:00.122895 (0.245400 s / iter per device, on 2 devices)
[04/05 01:51:33] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:29 (0.121321 s / iter per device, on 2 devices)
[04/05 01:59:16] detectron2 INFO: Rank of current process: 1. World size: 2
[04/05 01:59:17] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/05 01:59:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[04/05 01:59:17] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 6 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 17 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 17 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 16
  # MAX_ITER: 65000 #origin
  MAX_ITER: 300 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[04/05 01:59:17] detectron2.utils.env INFO: Using a generated random seed 19753674
[04/05 01:59:18] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[04/05 01:59:19] detectron2.data.build INFO: Using training sampler TrainingSampler
[04/05 01:59:19] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 01:59:19] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[04/05 01:59:19] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[04/05 01:59:19] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 01:59:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 01:59:19] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[04/05 01:59:20] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[04/05 01:59:20] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[04/05 01:59:20] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[04/05 01:59:20] detectron2.engine.train_loop INFO: Starting training from iteration 0
[04/05 02:13:40] detectron2.engine.hooks INFO: Overall training speed: 298 iterations in 0:13:57 (2.8087 s / it)
[04/05 02:13:40] detectron2.engine.hooks INFO: Total training time: 0:13:57 (0:00:00 on hooks)
[04/05 02:13:40] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[04/05 02:13:40] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 02:13:40] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[04/05 02:13:40] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[04/05 02:13:40] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[04/05 02:13:54] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0103 s/iter. Inference: 0.1645 s/iter. Eval: 0.1937 s/iter. Total: 0.3685 s/iter. ETA=0:01:28
[04/05 02:13:59] detectron2.evaluation.evaluator INFO: Inference done 26/250. Dataloading: 0.0111 s/iter. Inference: 0.1574 s/iter. Eval: 0.1895 s/iter. Total: 0.3582 s/iter. ETA=0:01:20
[04/05 02:14:05] detectron2.evaluation.evaluator INFO: Inference done 41/250. Dataloading: 0.0106 s/iter. Inference: 0.1576 s/iter. Eval: 0.1875 s/iter. Total: 0.3560 s/iter. ETA=0:01:14
[04/05 02:14:12] detectron2.evaluation.evaluator INFO: Inference done 55/250. Dataloading: 0.0111 s/iter. Inference: 0.2040 s/iter. Eval: 0.1840 s/iter. Total: 0.3993 s/iter. ETA=0:01:17
[04/05 02:14:17] detectron2.evaluation.evaluator INFO: Inference done 71/250. Dataloading: 0.0107 s/iter. Inference: 0.1896 s/iter. Eval: 0.1800 s/iter. Total: 0.3805 s/iter. ETA=0:01:08
[04/05 02:14:22] detectron2.evaluation.evaluator INFO: Inference done 87/250. Dataloading: 0.0104 s/iter. Inference: 0.1807 s/iter. Eval: 0.1761 s/iter. Total: 0.3675 s/iter. ETA=0:00:59
[04/05 02:14:27] detectron2.evaluation.evaluator INFO: Inference done 103/250. Dataloading: 0.0103 s/iter. Inference: 0.1751 s/iter. Eval: 0.1734 s/iter. Total: 0.3590 s/iter. ETA=0:00:52
[04/05 02:14:32] detectron2.evaluation.evaluator INFO: Inference done 122/250. Dataloading: 0.0097 s/iter. Inference: 0.1682 s/iter. Eval: 0.1673 s/iter. Total: 0.3454 s/iter. ETA=0:00:44
[04/05 02:14:37] detectron2.evaluation.evaluator INFO: Inference done 142/250. Dataloading: 0.0091 s/iter. Inference: 0.1623 s/iter. Eval: 0.1602 s/iter. Total: 0.3318 s/iter. ETA=0:00:35
[04/05 02:14:42] detectron2.evaluation.evaluator INFO: Inference done 163/250. Dataloading: 0.0086 s/iter. Inference: 0.1571 s/iter. Eval: 0.1539 s/iter. Total: 0.3198 s/iter. ETA=0:00:27
[04/05 02:14:48] detectron2.evaluation.evaluator INFO: Inference done 184/250. Dataloading: 0.0081 s/iter. Inference: 0.1530 s/iter. Eval: 0.1490 s/iter. Total: 0.3103 s/iter. ETA=0:00:20
[04/05 02:14:53] detectron2.evaluation.evaluator INFO: Inference done 206/250. Dataloading: 0.0078 s/iter. Inference: 0.1494 s/iter. Eval: 0.1448 s/iter. Total: 0.3021 s/iter. ETA=0:00:13
[04/05 02:14:58] detectron2.evaluation.evaluator INFO: Inference done 228/250. Dataloading: 0.0075 s/iter. Inference: 0.1468 s/iter. Eval: 0.1413 s/iter. Total: 0.2957 s/iter. ETA=0:00:06
[04/05 02:15:03] detectron2.evaluation.evaluator INFO: Inference done 250/250. Dataloading: 0.0072 s/iter. Inference: 0.1444 s/iter. Eval: 0.1380 s/iter. Total: 0.2898 s/iter. ETA=0:00:00
[04/05 02:15:04] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:11.879058 (0.293384 s / iter per device, on 2 devices)
[04/05 02:15:04] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:35 (0.144402 s / iter per device, on 2 devices)
[04/05 05:40:06] detectron2 INFO: Rank of current process: 1. World size: 2
[04/05 05:40:07] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.161.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/05 05:40:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=['datasets/cityscapes/leftImg8bit/train/'], machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[04/05 05:40:07] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 6 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 17 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 17 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 16
  # MAX_ITER: 65000 #origin
  MAX_ITER: 300 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[04/05 05:40:07] detectron2.utils.env INFO: Using a generated random seed 9995679
[04/05 05:40:08] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[04/05 05:40:09] detectron2.data.build INFO: Using training sampler TrainingSampler
[04/05 05:40:09] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 05:40:09] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[04/05 05:40:09] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[04/05 05:40:09] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 05:40:09] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[04/05 05:40:09] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[04/05 05:40:09] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[04/05 05:40:09] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[04/05 05:40:09] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[04/05 05:40:09] detectron2.engine.train_loop INFO: Starting training from iteration 0
[04/05 05:53:14] detectron2.engine.hooks INFO: Overall training speed: 298 iterations in 0:12:34 (2.5327 s / it)
[04/05 05:53:14] detectron2.engine.hooks INFO: Total training time: 0:12:34 (0:00:00 on hooks)
[04/05 05:53:15] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[04/05 05:53:15] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/05 05:53:15] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[04/05 05:53:15] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[04/05 05:53:15] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[04/05 05:53:31] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0135 s/iter. Inference: 0.1406 s/iter. Eval: 0.1946 s/iter. Total: 0.3487 s/iter. ETA=0:01:23
[04/05 05:53:36] detectron2.evaluation.evaluator INFO: Inference done 30/250. Dataloading: 0.0079 s/iter. Inference: 0.1305 s/iter. Eval: 0.1479 s/iter. Total: 0.2865 s/iter. ETA=0:01:03
[04/05 05:53:42] detectron2.evaluation.evaluator INFO: Inference done 50/250. Dataloading: 0.0065 s/iter. Inference: 0.1273 s/iter. Eval: 0.1408 s/iter. Total: 0.2747 s/iter. ETA=0:00:54
[04/05 05:53:47] detectron2.evaluation.evaluator INFO: Inference done 71/250. Dataloading: 0.0060 s/iter. Inference: 0.1251 s/iter. Eval: 0.1352 s/iter. Total: 0.2665 s/iter. ETA=0:00:47
[04/05 05:53:52] detectron2.evaluation.evaluator INFO: Inference done 92/250. Dataloading: 0.0058 s/iter. Inference: 0.1245 s/iter. Eval: 0.1299 s/iter. Total: 0.2602 s/iter. ETA=0:00:41
[04/05 05:53:57] detectron2.evaluation.evaluator INFO: Inference done 113/250. Dataloading: 0.0056 s/iter. Inference: 0.1241 s/iter. Eval: 0.1265 s/iter. Total: 0.2563 s/iter. ETA=0:00:35
[04/05 05:54:02] detectron2.evaluation.evaluator INFO: Inference done 134/250. Dataloading: 0.0055 s/iter. Inference: 0.1242 s/iter. Eval: 0.1242 s/iter. Total: 0.2540 s/iter. ETA=0:00:29
[04/05 05:54:07] detectron2.evaluation.evaluator INFO: Inference done 156/250. Dataloading: 0.0054 s/iter. Inference: 0.1240 s/iter. Eval: 0.1220 s/iter. Total: 0.2516 s/iter. ETA=0:00:23
[04/05 05:54:12] detectron2.evaluation.evaluator INFO: Inference done 178/250. Dataloading: 0.0053 s/iter. Inference: 0.1237 s/iter. Eval: 0.1201 s/iter. Total: 0.2492 s/iter. ETA=0:00:17
[04/05 05:54:17] detectron2.evaluation.evaluator INFO: Inference done 200/250. Dataloading: 0.0053 s/iter. Inference: 0.1233 s/iter. Eval: 0.1188 s/iter. Total: 0.2474 s/iter. ETA=0:00:12
[04/05 05:54:23] detectron2.evaluation.evaluator INFO: Inference done 222/250. Dataloading: 0.0052 s/iter. Inference: 0.1231 s/iter. Eval: 0.1177 s/iter. Total: 0.2461 s/iter. ETA=0:00:06
[04/05 05:54:28] detectron2.evaluation.evaluator INFO: Inference done 244/250. Dataloading: 0.0052 s/iter. Inference: 0.1230 s/iter. Eval: 0.1165 s/iter. Total: 0.2447 s/iter. ETA=0:00:01
[04/05 05:54:30] detectron2.evaluation.evaluator INFO: Total inference time: 0:01:00.758687 (0.247995 s / iter per device, on 2 devices)
[04/05 05:54:30] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:30 (0.122815 s / iter per device, on 2 devices)
[04/10 06:44:45] detectron2 INFO: Rank of current process: 1. World size: 2
[04/10 06:44:46] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            linux
Python                  3.7.16 (default, Jan 17 2023, 22:20:44) [GCC 11.2.0]
numpy                   1.21.6
detectron2              0.6 @/home/ubuntu/hm/PanopticFCN-main/cityscapes/tools_d2_cityscapes/detectron2/detectron2
Compiler                GCC 9.4
CUDA compiler           CUDA 11.1
detectron2 arch flags   8.6
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.12.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           Yes
GPU 0,1,2,3             NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version          470.182.03
CUDA_HOME               /usr/local/cuda-11.1
Pillow                  9.4.0
torchvision             0.13.1+cu113 @/home/ubuntu/dk/anaconda3/envs/pan_FCN_hm/lib/python3.7/site-packages/torchvision
torchvision arch flags  3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.6.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.3
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5  (built against CUDA 11.1)
    - Built with CuDNN 8.3.2
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.3.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.12.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

[04/10 06:44:46] detectron2 INFO: Command line arguments: Namespace(config_file='configs/cityscapes/PanopticFCN-R50-cityscapes.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=False, input=None, machine_rank=0, num_gpus=2, num_machines=1, opts=[], output=None, resume=False)
[04/10 06:44:46] detectron2 INFO: Contents of args.config_file=configs/cityscapes/PanopticFCN-R50-cityscapes.yaml:
MODEL:
  META_ARCHITECTURE: "PanopticFCN"
  WEIGHTS: "detectron2://ImageNetPretrained/MSRA/R-50.pkl"
  # WEIGHTS: "data/pretrained/R-50.pkl"
  MASK_ON: True
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RESNETS:
    DEPTH: 50
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]
  FPN:
    IN_FEATURES: ["res2", "res3", "res4", "res5"]
  LOSS_WEIGHT:
    SEGMENT: 4.0
  POSITION_HEAD:
    THING:
      NUM_CLASSES: 8 #origin
      # NUM_CLASSES: 6 #HM
      THRES: 0.01
      TOP_NUM: 200
    STUFF:
      THRES: 0.1
      NUM_CLASSES: 19 #origin
      # NUM_CLASSES: 17 #HM
      WITH_THING: False  # Check that this is not a problem
      # WITH_THING: True #HM
      ALL_CLASSES: True
  SEM_SEG_HEAD:
    NUM_CLASSES: 19 #origin
    # NUM_CLASSES: 17 #HM
  KERNEL_HEAD:
    INSTANCE_SCALES: ((1, 128), (64, 256), (128, 512), (256, 1024), (512, 2048),)
  TENSOR_DIM: 150  # Adapted because max inst. per img > 100
  INFERENCE:
    INST_THRES: 0.5
    SIMILAR_THRES: 0.97
    COMBINE:
      STUFF_AREA_LIMIT: 2048
DATASETS:
  NAME: "Cityscapes"
  TRAIN: ("cityscapes_fine_panoptic_train_separated",)
  TEST: ("cityscapes_fine_panoptic_val_separated",)
DATALOADER:
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 16
SOLVER:
  BASE_LR: 0.02
  WEIGHT_DECAY: 1e-4
  LR_SCHEDULER_NAME: "WarmupPolyLR"
  POLY_LR_POWER: 0.9
  WARMUP_ITERS: 1000
  WARMUP_FACTOR: 0.001
  WARMUP_METHOD: "linear"
  CLIP_GRADIENTS:
    ENABLED: True
    CLIP_VALUE: 15.0
  IMS_PER_BATCH: 16
  # MAX_ITER: 65000 #origin
  MAX_ITER: 300 #HM
  CHECKPOINT_PERIOD: 20000
INPUT:
  MIN_SIZE_TRAIN: (512, 768, 1024, 1152, 1216, 1344, 1408, 1536, 1664, 1728, 1856, 1920, 2048) #origin
  # MIN_SIZE_TRAIN: (512, 2048) #HM
  MIN_SIZE_TRAIN_SAMPLING: "choice" #origin
  # MIN_SIZE_TRAIN_SAMPLING: "range" #HM
  MIN_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 4096
  MAX_SIZE_TEST: 2048
  CROP:
    MINIMUM_INST_AREA: 1
    ENABLED: True
    TYPE: "absolute" #origin
    # TYPE: "with_instance" #HM
    SIZE: (512, 1024) # original
    # SIZE: (256, 512)
  MASK_FORMAT: "bitmask"
VERSION: 2


[04/10 06:44:46] detectron2.utils.env INFO: Using a generated random seed 46571221
[04/10 06:44:47] detectron2.engine.defaults INFO: Model:
PanopticFCN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelP6P7fromP5(
      (p6): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
      (p7): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
    )
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (semantic_fpn): SemanticFPN(
    (p2): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (p3): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p4): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
    )
    (p5): Sequential(
      (0): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): Upsample(scale_factor=2.0, mode=bilinear)
      (2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (3): Upsample(scale_factor=2.0, mode=bilinear)
      (4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (5): Upsample(scale_factor=2.0, mode=bilinear)
    )
  )
  (position_head): PositionHead(
    (position_head): SingleHead(
      (position_head_head_1): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_2): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
      (position_head_head_3): ModulatedDeformConvWithOff(
        (offset_mask_conv): Conv2d(256, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (dcnv2): ModulatedDeformConv(
          in_channels=256, out_channels=256, kernel_size=(3, 3), stride=1, padding=1, dilation=1, groups=1, deformable_groups=1, bias=False
          (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
        )
      )
    )
    (out_inst): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (out_sem): Conv2d(256, 19, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (kernel_head): KernelHead(
    (kernel_head): SingleHead(
      (kernel_head_head_1): Conv2d(
        258, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (kernel_head_head_3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (out_conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  )
  (feature_encoder): FeatureEncoder(
    (encode_head): SingleHead(
      (encode_head_head_1): Conv2d(258, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (encode_head_head_3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    )
  )
  (thing_generator): ThingGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
  (stuff_generator): StuffGenerator(
    (embed_extractor): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))
  )
)
[04/10 06:44:47] detectron2.data.build INFO: Using training sampler TrainingSampler
[04/10 06:44:47] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/10 06:44:47] detectron2.data.common INFO: Serializing 2975 elements to byte tensors and concatenating them all ...
[04/10 06:44:47] detectron2.data.common INFO: Serialized dataset takes 4.12 MiB
[04/10 06:44:47] detectron2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from detectron2://ImageNetPretrained/MSRA/R-50.pkl ...
[04/10 06:44:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /home/ubuntu/.torch/iopath_cache/detectron2/ImageNetPretrained/MSRA/R-50.pkl ...
[04/10 06:44:48] detectron2.checkpoint.c2_model_loading INFO: Renaming Caffe2 weights ......
[04/10 06:44:48] detectron2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone.bottom_up:
| Names in Model    | Names in Checkpoint      | Shapes                                          |
|:------------------|:-------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2_0_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2_0_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2_0_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2_0_branch1_{bn_*,w}  | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2_1_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2_1_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2_1_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2_2_branch2a_{bn_*,w} | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2_2_branch2b_{bn_*,w} | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2_2_branch2c_{bn_*,w} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3_0_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3_0_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3_0_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3_0_branch1_{bn_*,w}  | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3_1_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3_1_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3_1_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3_2_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3_2_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3_2_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3_3_branch2a_{bn_*,w} | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3_3_branch2b_{bn_*,w} | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3_3_branch2c_{bn_*,w} | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4_0_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4_0_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4_0_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4_0_branch1_{bn_*,w}  | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4_1_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4_1_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4_1_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4_2_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4_2_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4_2_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4_3_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4_3_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4_3_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4_4_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4_4_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4_4_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4_5_branch2a_{bn_*,w} | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4_5_branch2b_{bn_*,w} | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4_5_branch2c_{bn_*,w} | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5_0_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5_0_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5_0_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5_0_branch1_{bn_*,w}  | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5_1_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5_1_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5_1_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5_2_branch2a_{bn_*,w} | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5_2_branch2b_{bn_*,w} | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5_2_branch2c_{bn_*,w} | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.norm.* | res_conv1_bn_*           | (64,) (64,) (64,) (64,)                         |
| stem.conv1.weight | conv1_w                  | (64, 3, 7, 7)                                   |
[04/10 06:44:48] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbackbone.fpn_lateral2.{bias, weight}[0m
[34mbackbone.fpn_lateral3.{bias, weight}[0m
[34mbackbone.fpn_lateral4.{bias, weight}[0m
[34mbackbone.fpn_lateral5.{bias, weight}[0m
[34mbackbone.fpn_output2.{bias, weight}[0m
[34mbackbone.fpn_output3.{bias, weight}[0m
[34mbackbone.fpn_output4.{bias, weight}[0m
[34mbackbone.fpn_output5.{bias, weight}[0m
[34mbackbone.top_block.p6.{bias, weight}[0m
[34mbackbone.top_block.p7.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_1.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_2.{bias, weight}[0m
[34mfeature_encoder.encode_head.encode_head_head_3.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_1.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_2.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_2.weight[0m
[34mkernel_head.kernel_head.kernel_head_head_3.norm.{bias, weight}[0m
[34mkernel_head.kernel_head.kernel_head_head_3.weight[0m
[34mkernel_head.out_conv.{bias, weight}[0m
[34mposition_head.out_inst.{bias, weight}[0m
[34mposition_head.out_sem.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_1.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_1.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_2.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_2.offset_mask_conv.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.norm.{bias, weight}[0m
[34mposition_head.position_head.position_head_head_3.dcnv2.weight[0m
[34mposition_head.position_head.position_head_head_3.offset_mask_conv.{bias, weight}[0m
[34msemantic_fpn.p2.0.norm.{bias, weight}[0m
[34msemantic_fpn.p2.0.weight[0m
[34msemantic_fpn.p3.0.norm.{bias, weight}[0m
[34msemantic_fpn.p3.0.weight[0m
[34msemantic_fpn.p4.0.norm.{bias, weight}[0m
[34msemantic_fpn.p4.0.weight[0m
[34msemantic_fpn.p4.2.norm.{bias, weight}[0m
[34msemantic_fpn.p4.2.weight[0m
[34msemantic_fpn.p5.0.norm.{bias, weight}[0m
[34msemantic_fpn.p5.0.weight[0m
[34msemantic_fpn.p5.2.norm.{bias, weight}[0m
[34msemantic_fpn.p5.2.weight[0m
[34msemantic_fpn.p5.4.norm.{bias, weight}[0m
[34msemantic_fpn.p5.4.weight[0m
[34mstuff_generator.embed_extractor.{bias, weight}[0m
[34mthing_generator.embed_extractor.{bias, weight}[0m
[04/10 06:44:48] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mfc1000.{bias, weight}[0m
  [35mstem.conv1.bias[0m
[04/10 06:44:48] detectron2.engine.train_loop INFO: Starting training from iteration 0
[04/10 06:53:21] detectron2.engine.hooks INFO: Overall training speed: 298 iterations in 0:08:15 (1.6632 s / it)
[04/10 06:53:21] detectron2.engine.hooks INFO: Total training time: 0:08:15 (0:00:00 on hooks)
[04/10 06:53:21] detectron2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(1024, 1024), max_size=2048, sample_style='choice')]
[04/10 06:53:21] detectron2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[04/10 06:53:21] detectron2.data.common INFO: Serializing 500 elements to byte tensors and concatenating them all ...
[04/10 06:53:21] detectron2.data.common INFO: Serialized dataset takes 0.74 MiB
[04/10 06:53:21] detectron2.evaluation.evaluator INFO: Start inference on 250 batches
[04/10 06:53:28] detectron2.evaluation.evaluator INFO: Inference done 11/250. Dataloading: 0.0067 s/iter. Inference: 0.1300 s/iter. Eval: 0.1228 s/iter. Total: 0.2595 s/iter. ETA=0:01:02
[04/10 06:53:33] detectron2.evaluation.evaluator INFO: Inference done 33/250. Dataloading: 0.0041 s/iter. Inference: 0.1194 s/iter. Eval: 0.1144 s/iter. Total: 0.2380 s/iter. ETA=0:00:51
[04/10 06:53:38] detectron2.evaluation.evaluator INFO: Inference done 55/250. Dataloading: 0.0040 s/iter. Inference: 0.1170 s/iter. Eval: 0.1142 s/iter. Total: 0.2353 s/iter. ETA=0:00:45
[04/10 06:53:43] detectron2.evaluation.evaluator INFO: Inference done 77/250. Dataloading: 0.0040 s/iter. Inference: 0.1164 s/iter. Eval: 0.1137 s/iter. Total: 0.2343 s/iter. ETA=0:00:40
[04/10 06:53:48] detectron2.evaluation.evaluator INFO: Inference done 99/250. Dataloading: 0.0040 s/iter. Inference: 0.1166 s/iter. Eval: 0.1135 s/iter. Total: 0.2342 s/iter. ETA=0:00:35
[04/10 06:53:53] detectron2.evaluation.evaluator INFO: Inference done 121/250. Dataloading: 0.0040 s/iter. Inference: 0.1168 s/iter. Eval: 0.1137 s/iter. Total: 0.2346 s/iter. ETA=0:00:30
[04/10 06:53:58] detectron2.evaluation.evaluator INFO: Inference done 143/250. Dataloading: 0.0040 s/iter. Inference: 0.1168 s/iter. Eval: 0.1136 s/iter. Total: 0.2345 s/iter. ETA=0:00:25
[04/10 06:54:04] detectron2.evaluation.evaluator INFO: Inference done 165/250. Dataloading: 0.0040 s/iter. Inference: 0.1167 s/iter. Eval: 0.1137 s/iter. Total: 0.2345 s/iter. ETA=0:00:19
[04/10 06:54:09] detectron2.evaluation.evaluator INFO: Inference done 187/250. Dataloading: 0.0040 s/iter. Inference: 0.1168 s/iter. Eval: 0.1136 s/iter. Total: 0.2345 s/iter. ETA=0:00:14
[04/10 06:54:14] detectron2.evaluation.evaluator INFO: Inference done 209/250. Dataloading: 0.0040 s/iter. Inference: 0.1168 s/iter. Eval: 0.1129 s/iter. Total: 0.2339 s/iter. ETA=0:00:09
[04/10 06:54:19] detectron2.evaluation.evaluator INFO: Inference done 231/250. Dataloading: 0.0040 s/iter. Inference: 0.1168 s/iter. Eval: 0.1127 s/iter. Total: 0.2336 s/iter. ETA=0:00:04
[04/10 06:54:24] detectron2.evaluation.evaluator INFO: Total inference time: 0:00:58.024051 (0.236833 s / iter per device, on 2 devices)
[04/10 06:54:24] detectron2.evaluation.evaluator INFO: Total inference pure compute time: 0:00:28 (0.116634 s / iter per device, on 2 devices)
